\documentclass[12pt,a4paper]{article}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{float}
\usepackage{geometry}
\geometry{margin=1in}

\title{End-to-End Stock Risk Forecasting \& Recommendation System \\ \large A Comprehensive MLOps Implementation}
\author{John Doe \\ MLOps Course, Fall 2025 \\ Domain: Economics \& Finance}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
This report details the design and implementation of an end-to-end Machine Learning Operations (MLOps) system capable of forecasting daily stock returns, classifying asset risk, and recommending similar equities. The system integrates a robust offline training pipeline with an online inference service. Leveraging Alpha Vantage for real-time financial data, the solution utilizes Scikit-Learn for modeling, Prefect for workflow orchestration, FastAPI for model serving, and Docker for containerized deployment, ensuring a reproducible and scalable architecture.
\end{abstract}

\section{Introduction}
Financial markets are characterized by high volatility and noise, making manual risk assessment challenging. Institutional investors require automated systems to quantify risk and identify diversification opportunities. This project addresses these needs by building a unified system that forecasts short-term market movements, categorizes stocks by volatility risk, and groups assets with similar behavioral patterns.

\section{System Overview}
The solution is architected as a two-stage system: an Offline Training Pipeline for model generation and an Online Inference Service for real-time predictions.

\subsection{Core Technologies}
\begin{itemize}
    \item \textbf{Data Provider:} Alpha Vantage API (Time Series Daily).
    \item \textbf{Machine Learning:} Scikit-Learn (Random Forest, Gradient Boosting, PCA, K-Means).
    \item \textbf{Orchestration:} Prefect (Flow management, retries, logging).
    \item \textbf{Serving:} FastAPI (High-performance asynchronous API).
    \item \textbf{Infrastructure:} Docker (Containerization) \& GitHub Actions (CI/CD).
\end{itemize}

\subsection{API Interface}
The deployed service exposes the following RESTful endpoints:
\begin{itemize}
    \item \texttt{POST /predict\_risk}: Returns risk classification (Low, Medium, High) and probability.
    \item \texttt{POST /predict\_return}: Forecasts the next-day percentage return.
    \item \texttt{GET /recommend\_similar}: Suggets similar stocks based on latent feature clusters.
    \item \texttt{GET /metrics}: Exposes the latest model evaluation metrics.
\end{itemize}

\section{System Architecture & Data Flow}
The architecture ensures separation of concerns between training and serving, linked by a versioned model registry.

\subsection{End-to-End Data Flow}
The pipeline follows a linear DAG (Directed Acyclic Graph) structure:
\begin{enumerate}
    \item \textbf{Ingestion:} The \texttt{ingestion} module fetches daily OHLCV data for the target universe (AAPL, MSFT, GOOGL, AMZN, TSLA) from Alpha Vantage.
    \item \textbf{Feature Engineering:} Raw prices are transformed into stationary features, including lagged returns ($R_{t-1}, \dots, R_{t-5}$), rolling volatility (5-day, 20-day), and momentum indicators.
    \item \textbf{Training \& Evaluation:} Models are trained on historical data and evaluated against a hold-out test set. Metrics are logged to JSON artifacts.
    \item \textbf{Model Registry:} Trained artifacts (serialized via Joblib) are versioned by timestamp and stored in the \texttt{models/} directory.
    \item \textbf{Inference:} The FastAPI service loads the latest model version into memory at startup to serve low-latency requests.
\end{enumerate}

\subsection{Orchestration & CI/CD}
\textbf{Prefect} manages the training workflow, handling task dependencies and alerting on failure. \textbf{GitHub Actions} provides Continuous Integration and Deployment: upon every code push, the workflow triggers automated unit tests (PyTest), validates code integrity, and builds a production-ready Docker image, ensuring that only verified code reaches deployment.

\section{Methodology}

\subsection{Data Source \& Constraints}
The dataset consists of daily time-series data for five major technology tickers. Due to API rate limits and tier restrictions, the data history is constrained to the ``Compact'' mode (approximately the last 100 trading days). This "cold start" constraint poses a significant challenge for model generalization, requiring robust regularization techniques.

\subsection{Feature Engineering Strategy}
To capture market dynamics, we engineered the following features:
\begin{itemize}
    \item \textbf{Lagged Returns:} Capturing autocorrelation in price movements.
    \item \textbf{Volatility:} Defined as the rolling standard deviation of returns ($\sigma_{20d}$).
    \item \textbf{Target Definitions:}
    \begin{itemize}
        \item \textit{Regression Target:} Next-day return ($R_{t+1}$).
        \item \textit{Classification Target:} Risk labels (0=Low, 1=Medium, 2=High) derived analytically from volatility quantiles ($0.33, 0.66$) rather than subjective human annotation.
    \end{itemize}
\end{itemize}

\subsection{Machine Learning Models}
\subsubsection{Regression (Return Forecasting)}
We utilize a \textbf{Random Forest Regressor} within a Scikit-Learn Pipeline including \texttt{StandardScaler}. The objective is to minimize Root Mean Squared Error (RMSE):
\begin{equation}
    RMSE = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}
\end{equation}

\subsubsection{Classification (Risk Profiling)}
A \textbf{Random Forest Classifier} predicts the risk category. Evaluation focuses on Accuracy and F1-Score to ensure balanced detection of high-risk assets.

\subsubsection{Unsupervised Learning}
To enable recommendation, we apply \textbf{Principal Component Analysis (PCA)} to reduce feature dimensionality, followed by \textbf{K-Means Clustering} to identify cohorts of stocks with similar market behavior.

\section{Experiments \& Observations}

\subsection{Experimental Setup}
Validation was performed using a strict \textbf{Time-Series Split}: the most recent $N=30$ days of data were held out for testing, while the preceding days were used for training. This prevents "look-ahead bias," a critical error in financial modeling where future information leaks into the past.

\subsection{Challenge 1: Data Sparsity}
\textbf{Observation:} Restricting the input to 100 days resulted in a "small $N$, large $P$" problem where the number of features approached the number of samples, increasing overfitting risk.
\newline
\textbf{Solution:} We enforced strict regularization (limited tree depth) and validated data integrity using custom drift detection scripts in \texttt{ml/drift.py}.

\subsection{Challenge 2: Regression Overfitting}
\textbf{Experiment A (Gradient Boosting):} Initially, a Gradient Boosting Regressor was employed. It significantly overfitted the training noise, yielding a negative $R^2$ on the test set ($\approx -0.24$), performing worse than a mean baseline.
\newline
\textbf{Experiment B (Regularized Random Forest):} We switched to a Random Forest with \texttt{min\_samples\_leaf=10} to enforce "grouping" of observations.
\newline
\textbf{Result:} The model stabilized. While the Test $R^2$ remains slightly negative ($\approx -0.06$), this is an improvement, indicating the model is effectively reverting to the mean—a rational strategy in highly unpredictable short-term markets.

\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{Task} & \textbf{Metric} & \textbf{Value} \\
\hline
Regression & RMSE & 0.019 \\
Regression & Test $R^2$ & -0.06 (Mean-reverting) \\
Classification & Accuracy & 0.98 \\
Classification & F1-Score & 0.98 \\
\hline
\end{tabular}
\caption{Final Model Performance Metrics}
\end{table}

\textbf{Classification Success:} In contrast to regression, the classification model achieved near-perfect accuracy (>98\%). Since the labels are derived from volatility (a more stable property than price), the model successfully learned to distinguish low-volatility periods from high-volatility ones.

\section{MLOps \& Monitoring}
To satisfy production requirements, the system implements:
\begin{itemize}
    \item \textbf{Automated Notifications:} The Prefect orchestration layer triggers alerts upon pipeline completion or failure.
    \item \textbf{Drift Detection:} The \texttt{ml/drift.py} module runs pre-training checks, warning if feature distributions shift significantly or if data integrity (NaNs) is compromised.
    \item \textbf{Containerization:} A multi-stage Docker build ensures the application runs identically in development and production environments.
\end{itemize}

\section{Conclusion}
We have successfully deployed a comprehensive MLOps MLOps system for stock analysis. The project demonstrates the utility of automated orchestration and CI/CD in maintaining ML pipelines. While precise return forecasting remains a fundamental challenge in quantitative finance—evidenced by our conservative regression results—the system provides reliable, actionable insights through risk classification and asset recommendation.

\end{document}
