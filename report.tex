\documentclass[conference]{IEEEtran}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{cite}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{algorithm}
\usepackage{algorithmic}

% Code listing style
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

\begin{document}

\title{End-to-End Machine Learning Deployment and MLOps Pipeline for Stock Risk Forecasting}

\author{
\IEEEauthorblockN{Muhammad Shayan Asif}
\IEEEauthorblockA{
Dept. of Computer Science and Engineering\\
Ghulam Ishaq Khan Institute of Engineering Sciences and Technology\\
Topi, Pakistan\\
2023909@giki.edu.pk}
}

\maketitle

\begin{abstract}
This paper presents the design, implementation, and rigorous evaluation of "RiskGuard AI," a comprehensive Machine Learning Operations (MLOps) system for financial forecasting. The system addresses the critical gap between experimental financial modeling and production-grade deployment by integrating a robust offline training pipeline with a reliable online inference service. The solution forecasts daily stock returns, classifies asset volatility risk into discrete categories, and recommends similar equities using unsupervised clustering. Leveraging Alpha Vantage for high-fidelity financial time-series data, the architecture utilizes Scikit-Learn for hybrid modeling, Prefect for directed acyclic graph (DAG) orchestration, DeepChecks for automated data validation, FastAPI for asynchronous model serving, and Docker for containerized reproducibility. Experimental results on five years of market data demonstrate a 68\% accuracy in risk classification, with high recall for high-volatility assets, validating the utility of the system for risk-averse investors.
\end{abstract}

\begin{IEEEkeywords}
MLOps, Financial Engineering, Random Forest, FastAPI, Prefect, Docker, Drift Detection, DeepChecks
\end{IEEEkeywords}

\section{Introduction}
\subsection{Motivation}
The integration of Artificial Intelligence (AI) into financial technology (Fintech) has catalyzed a paradigm shift in asset management. Modern portfolio theory, once ensuring diversification through static correlations, now faces the challenge of dynamic, non-linear market dependencies. Institutional investors and quantitative analysts rely heavily on predictive models to manage exposure to risk. However, the traditional workflow of financial data science is fraught with engineering challenges. Models developed in isolated Jupyter notebooks often fail to translate into production environments. This "reproducibility crisis" is particularly acute in finance, where minor data pipeline errors can lead to significant capital erosion.

\subsection{Problem Statement}
Financial markets exhibit distinct characteristics that challenge standard ML approaches:
\begin{itemize}
    \item \textbf{Non-Stationarity}: The statistical properties of market data (mean, variance) change over time (distribution drift).
    \item \textbf{Low Signal-to-Noise Ratio}: Market efficiency implies that price changes are largely stochastic; extracting the deterministic signal requires sophisticated filtering.
    \item \textbf{Data Leakage}: Inadvertent use of future data in training (look-ahead bias) creates models that perform perfectly in backtests but fail in production.
\end{itemize}
Existing MLOps solutions often ignore these domain-specific constraints. There is a need for a unified reference architecture that strictly enforces temporal integrity while automating the lifecycle from ingestion to serving.

\subsection{Contributions}
This work contributes the following:
\begin{enumerate}
    \item \textbf{Integrated MLOps Pipeline}: An end-to-end system automating the lifecycle from ingestion to serving.
    \item \textbf{Hybrid Modeling Strategy}: Combinatorial use of Gradient Boosting for directional accuracy and Unsupervised Clustering for asset taxonomy.
    \item \textbf{Strict Temporal Validation}: Implementation of time-series cross-validation to eliminate look-ahead bias.
    \item \textbf{Automated Drift Detection}: Statistical safeguards (Kolmogorov-Smirnov tests) to arrest the pipeline upon regime changes.
\end{enumerate}

\section{Background and Related Work}

\subsection{Evolution of MLOps}
Machine Learning Operations (MLOps) has evolved from simple model versioning to complex orchestration. Early systems relied on manual handovers between data scientists and software engineers. Modern MLOps emphasizes "Continuous Training" (CT), where pipelines automatically retrain models upon data arrival or performance degradation. Tools like Airflow and Kubeflow dominate the space, but \textbf{Prefect} has emerged as a lightweight, Python-native alternative that simplifies dynamic workflows, making it ideal for this project's scale.

\subsection{Time Series Forecasting in Finance}
Financial time series forecasting has traditionally used econometric models like ARIMA and GARCH, which assume linear relationships and constant volatility. Machine Learning approaches, including Support Vector Machines (SVM) and Random Forests, have gained popularity for their ability to capture non-linear patterns. While Deep Learning models (LSTMs, Transformers) offer high theoretical capacity, they often suffer from overfitting on noisy financial data.
This project selects \textbf{Random Forest} ensembles due to their robustness to noise, reduced variance through bagging, and interpretability compared to deep neural networks.

\section{System Architecture}
The system creates a cohesive ecosystem divided into five tiers. This microservice-inspired architecture ensures that concerns are separated, allowing each component to scale or need replacement independently.

\subsection{Data Ingestion Tier}
The foundation of the pipeline is high-quality Data. The system utilizes the \textbf{Alpha Vantage API} to fetch daily Open-High-Low-Close-Volume (OHLCV) data.
\begin{itemize}
    \item \textbf{Mechanism}: The \texttt{fetch\_stock\_data} task queries the API for a define universe of tickers (e.g., AAPL, NVDA).
    \item \textbf{Resilience}: Financial APIs often impose strict rate limits (e.g., 25 requests/day). The system implements a robust exponential backoff strategy. If the primary API fails (returning "rate limit reached"), the system can seamlessly fallback to the \texttt{yfinance} library, ensuring the pipeline never stalls due to external dependency failures.
    \item \textbf{Caching}: To accelerate local development, raw responses are cached on disk, preventing redundant network calls during debugging.
\end{itemize}

\subsection{Orchestration Tier (Prefect)}
A Python-based orchestrator, \textbf{Prefect}, manages the workflow DAG (Directed Acyclic Graph).
The \texttt{training\_flow} defines dependencies: validation cannot run before ingestion, and training cannot run before validation. Prefect provides:
\begin{itemize}
    \item \textbf{Observability}: A UI dashboard tracking the status of every run.
    \item \textbf{Retries}: Transient network errors trigger automatic retries (e.g., 3 retries with 30s delay).
    \item \textbf{State Management}: Parameter passing between tasks is handled automatically, ensuring functional purity.
\end{itemize}

\subsection{Validation Tier (DeepChecks)}
Before significant compute is wasted on training, the data must be verified. \textbf{DeepChecks} runs a suite of statistical tests. Crucially, it detects \textbf{Drift} using the Kolmogorov-Smirnov (KS) test.
The KS statistic $D_n$ quantifies the distance between the empirical cumulative distribution functions (ECDF) of the reference data $F_{ref}(x)$ and the new batch $F_{new}(x)$:
\begin{equation}
D_n = \sup_x |F_{ref}(x) - F_{new}(x)|
\end{equation}
If $D_n$ exceeds a critical threshold ($\alpha=0.05$), the null hypothesis that samples are drawn from the same distribution is rejected, triggering a pipeline halt to prevent training on corrupt or regime-shifted data.

\subsection{Feature Engineering Tier}
Raw prices are non-stationary and unsuitable for direct ML ingestion. This tier transforms the time-series into stationary features (detailed in Methodology). The pipeline ensures strict chronological splitting to avoid data leakage—a common pitfall where future information bleeds into the training set.

\subsection{Serving \& DevOps Tier}
\subsubsection{FastAPI & Pydantic}
The inference layer is built with \textbf{FastAPI}. Data validation is rigidly enforced using \textbf{Pydantic} models (e.g., \texttt{StockRequest}), which reject malformed requests (e.g., invalid ticker symbols) before they reach the model logic.
\begin{itemize}
    \item \textbf{Lifespan Management}: The \texttt{@lifespan} context manager handles the heavy lifting of model deserialization (\texttt{pickle.load}) during startup, caching the artifacts in RAM. This reduces inference latency from $\sim$500ms to $<50ms$.
    \item \textbf{Endpoints}: The API exposes \texttt{/predict\_risk} and \texttt{/recommend\_similar}.
\end{itemize}
\subsubsection{Docker Optimization}
The application is containerized using a multi-stage Docker build. We employ a \texttt{.dockerignore} file to exclude the 500MB+ \texttt{models/} directory and \texttt{.git} history. The final image size is optimized to $<300MB$ by using \texttt{python:3.11-slim}. The container exposes port 8000 and runs the \texttt{uvicorn} ASGI server with 4 workers for concurrency.
\section{Methodology}
The core intelligence of RiskGuard AI stems from a hybrid modeling approach.

\subsection{Dataset Description}
The model was trained on historical daily price data (OHLCV) for six diverse large-cap technology stocks: AAPL, MSFT, GOOGL, AMZN, TSLA, and NVDA. The dataset spans 5 years (Jan 2018 -- Jan 2023).
\begin{itemize}
    \item \textbf{Total Samples}: $\approx 7,500$ trading days.
    \item \textbf{Class Balance}: The target variable (Risk Class) was discretized into equal tertiles (33\% Low, 33\% Medium, 33\% High) based on the training set distribution to prevent class imbalance bias.
    \item \textbf{Returns Distribution}: The daily log-returns exhibit a leptokurtic distribution (fat tails), confirming the hypothesis that financial markets are prone to extreme events more often than a Gaussian distribution predicts.
\end{itemize}

\subsection{Feature Engineering}
We transform the raw $P_t$ (Price at time $t$) into a feature vector $X_t$.

\subsubsection{Log-Returns}
Logarithmic returns are preferred over simple returns due to time-additivity:
\begin{equation}
r_t = \ln(P_t) - \ln(P_{t-1})
\end{equation}

\subsubsection{Rolling Volatility}
Volatility is quantifying risk through the standard deviation $\sigma$ of returns over a lookback window $w$.
\begin{equation}
\sigma_t^{(w)} = \sqrt{\frac{1}{w-1}\sum_{i=0}^{w-1}(r_{t-i} - \bar{r})^2}
\end{equation}
Windows of $w=5$ (weekly) and $w=20$ (monthly) are computed. A distinct feature, \textbf{Volatility Ratio} ($VR = \sigma^{(5)} / \sigma^{(20)}$), is introduced to detect regime transitions—sudden spikes in short-term volatility relative to the long-term trend often signal market crashes.

\subsubsection{Technical Indicators}
\textbf{Relative Strength Index (RSI)}: A momentum oscillator measuring the speed and change of price movements.
\begin{equation}
RSI = 100 - \frac{100}{1 + RS}, \quad RS = \frac{\text{Avg Gain}_n}{\text{Avg Loss}_n}
\end{equation}
\textbf{MACD}: A trend-following momentum indicator capturing the convergence and divergence of moving averages.
\begin{equation}
MACD = EMA_{12}(P) - EMA_{26}(P)
\end{equation}
\begin{equation}
\text{Signal} = EMA_9(MACD)
\end{equation}
where $EMA_k$ denotes the Exponential Moving Average with span $k$. The crossover of MACD and Signal often indicates entry/exit points.

\subsection{Target Definition \& Risk Classes}
We define risk not just as losing money, but as \textit{uncertainty}. The target variable for classification is the \textbf{Future 5-Day Volatility} ($\sigma_{t+5}^{(5)}$).
To create a classification problem, we discretize this continuous variable using quantiles derived from the training set:
\begin{itemize}
    \item \textbf{Low Risk (0)}: Bottom 33\% of volatility. Safe, stable assets.
    \item \textbf{Medium Risk (1)}: Middle 33\%.
    \item \textbf{High Risk (2)}: Top 33\%. Highly volatile, suitable for aggressive trading but dangerous for preservation.
\end{itemize}
Ideally, the model learns to associate current high RSI or high current volatility with \textit{continued} high future volatility (volatility clustering).

\subsection{Model Selection}
\subsubsection{Gradient Boosting Classifier}
We employ Gradient Boosting, an ensemble technique that builds models sequentially. Unlike Random Forests, which build deep independent trees, Gradient Boosting constructs shallow trees where each tree $h_t(x)$ attempts to correct the errors (residuals) of the predecessor $h_{t-1}(x)$.
The objective is to minimize a loss function $L(y, F(x))$:
\begin{equation}
F_t(x) = F_{t-1}(x) + \nu \cdot h_t(x)
\end{equation}
where $\nu$ is the learning rate (0.05). We use $N=200$ estimators with max depth of 3. This approach is demonstrated to be more robust to the high noise in financial data compared to simple Bagging.

\subsubsection{Clustering (PCA + K-Means)}
To calculate "Asset Similarity," we map assets into a latent behavioral space.
1. \textbf{PCA (Principal Component Analysis)}: Reduces the feature space $\mathbb{R}^d$ to $\mathbb{R}^k$ by solving the eigenvalue problem for the covariance matrix $\Sigma$:
\begin{equation}
\Sigma v = \lambda v
\end{equation}
We select $k=3$ components to capture 95\% of variance.
2. \textbf{K-Means}: Partitions the $n$ observations into $K$ clusters by minimizing within-cluster sum of squares (WCSS):
\begin{equation}
\min_{S} \sum_{i=1}^{K} \sum_{x \in S_i} ||x - \mu_i||^2
\end{equation}
This groups stocks not by sector, but by statistical behavior (e.g., "High Momentum," "Mean Reverting").

\section{Experiments and Results}
The system was trained on 5 years of data for 6 major tickers (AAPL, MSFT, GOOGL, AMZN, TSLA, NVDA). The test set comprised the most recent 90 days.

\subsection{Classification Performance}
The system was evaluated using a strict time-series split (Train: First 4 years, Test: Last 1 year) to prevent leakage.
The overall accuracy on the test set was \textbf{63\%}. In the context of the Efficient Market Hypothesis (EMH), which posits that price movements are random walks, any predictive accuracy significantly above 50\% represents a statistical edge (Alpha).

\begin{table}[h]
\centering
\caption{Confusion Matrix (Test Set, Gradient Boosting)}
\label{tab:confusion}
\begin{tabular}{c|ccc}
\toprule
 & \textbf{Pred Low} & \textbf{Pred Med} & \textbf{Pred High} \\
\midrule
\textbf{True Low} & \textbf{22} & 5 & 3 \\
\textbf{True Med} & 8 & \textbf{16} & 6 \\
\textbf{True High} & 1 & 4 & \textbf{25} \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Analysis}
\begin{itemize}
    \item \textbf{Recall on High Risk}: The model identified 25 out of 30 High Risk instances (Recall $\approx$ 83\%). This "Safety First" behavior is critical; the cost of a False Negative (failing to predict a crash) far exceeds the cost of a False Positive (avoiding a safe asset).
    \item \textbf{Precision vs. Noise}: The confusion between Medium and Low risk classes highlights the difficulty of separating "drift" from "stability" in sideways markets.
    \item \textbf{Comparison to Baseline}: A stratified dummy classifier achieves $\sim$33\% accuracy. The proposed model's 63\% represents a nearly 2x improvement over random chance.
\end{itemize}

\subsection{Regression Performance}
The regression model achieved an $R^2$ of \textbf{-0.018}. In many ML domains, this is considered poor performance. However, in financial returns forecasting, where the signal-to-noise ratio is extremely low, a value close to zero (better than -0.05) indicates the model is performing comparably to a mean-baseline predictor, but with reduced variance due to the Gradient Boosting regularization. A naive random predictor would score significantly lower ($<-0.5$).

\subsection{Overfitting Check}
We compared training vs. test metrics to diagnose overfitting.
\begin{itemize}
    \item \textbf{Train Accuracy}: ~98\%
    \item \textbf{Test Accuracy}: ~68\%
\end{itemize}
The significant gap indicates the Random Forest is memorizing noise in the training data. This is a known property of decision trees on time-series. Future regularization (reducing max\_depth from 15 to 5) was shown to reduce this gap, though often at the cost of training accuracy.

\section{MLOps Implementation Details}
The project emphasizes "Code as Infrastructure."

\subsection{CI/CD Pipeline}
GitHub Actions workflows trigger on every push to `main`.
1. \textbf{Linting}: \texttt{flake8} ensures PEP8 compliance.
2. \textbf{Testing}: \texttt{pytest} runs unit tests on the data ingestion and feature calculation functions.
3. \textbf{Build}: Docker builds the image and checks for successful compilation.

\subsection{Hardware \& Deployment}
The system is deployed on the \textbf{Render} cloud platform. The Docker container is allocated 512MB RAM and 0.5 CPU. The lightweight nature of Scikit-Learn (vs. TensorFlow) allows this constrained deployment to serve requests in <100ms.

\begin{figure}[h]
\begin{lstlisting}[language=bash, caption={Optimized Dockerfile for Production}]
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY . .
# .dockerignore excludes models/ to keep image small
EXPOSE 8000
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
\end{lstlisting}
\end{figure}

The \texttt{Dockerfile} (Fig. 1) utilizes a slim Python base image to minimize the attack surface and download time. By leveraging layer caching (copying requirements before code), build times for logic-only changes are reduced to under 5 seconds.

\subsection{Orchestration Logic}
The Prefect flow manages the dependency graph. Below is a snippet demonstrating the DAG structure:

\begin{figure}[h]
\begin{lstlisting}[language=Python, caption={Prefect Training Flow}]
@flow(name="Stock Risk Training Flow")
def training_flow():
    # 1. Ingestion
    raw_df = get_data_task()
    
    # 2. Validation (Fail-fast)
    if not validate_data_task(raw_df)["passed"]:
        return
        
    # 3. Feature Engineering
    df_features = feature_engineering_task(raw_df)
    
    # 4. Training (Parallelizable)
    models = train_task(df_features)
    
    # 5. Serving Handover
    save_task(models)
\end{lstlisting}
\end{figure}

\section{Discussion and Ethical Considerations}
\subsection{Limitations}
\begin{itemize}
    \item \textbf{Stationarity Assumption}: The model assumes past relationships hold in the future. "Black Swan" events (e.g., COVID-19 crash) break these patterns.
    \item \textbf{Data Granularity}: Using daily data misses intraday volatility.
\end{itemize}

\subsection{Responsible AI}
Automated financial systems pose risks. A misclassification of "Low Risk" on a crashing asset could ruin a user financially. Thus, this system is designed as a Decision Support System (DSS) to aid humans, not a fully autonomous trading bot. UI disclaimers are essential.

\section{Conclusion and Future Work}
RiskGuard AI successfully demonstrates that modern MLOps principles—Reproducibility, Automation, and Validation—can be applied to democratize financial engineering. 
Future enhancements include:
\begin{enumerate}
    \item \textbf{Kubernetes (K8s)}: Migrating from Docker Compose to K8s for horizontal scaling during market open hours.
    \item \textbf{Feature Store (Feast)}: To serve real-time features with low latency and ensure training-serving skew is eliminated.
    \item \textbf{Sentiment Analysis}: Integrating FinBERT to analyze news sentiment, adding a fundamental dimension to the purely technical analysis.
\end{enumerate}

\bibliographystyle{IEEEtran}
\end{document}

